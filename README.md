# ğŸ“§ Email Campaign Performance Optimization

Optimizing marketing campaigns is one of the most common and impactful tasks in data science. This project focuses on improving the performance of email-based campaigns using feature engineering, exploratory data analysis, and various machine learning models.

Emails are highly effective as they are *free*, **scalable**, and **personalizable**. The goal is to optimize emails based on **content**, **personalization**, **timing**, and **user behavior** to boost engagement rates.

---

##  Project Summary

- **Total Emails Sent**: 100,000  
- **Emails Opened**: 10,345  
- **Emails Clicked**: 2,119  
- **Open Rate**: 10.35%  
- **Click Rate**: 2.12%  
- **Click-Through Rate (CTR)**: 20.48% (clicks per open)

---

## ğŸ“Š Key Insights from Exploratory Data Analysis

Below are interesting behavioral patterns discovered across different segments:

### ğŸ”  Email Content & Personalization
- **Short Emails perform better**: 
  - **Open Rate**: 11.59% vs 9.12% (short vs long)
  - **Click Rate**: 2.39% vs 1.85%
- **Personalized Emails outperform Generic**:
  - **Open Rate**: 12.78% vs 7.93%
  - **Click Rate**: 2.73% vs 1.51%

### ğŸ•°ï¸ Time of Day Matters
- Best performance observed during **9 AM â€“ 12 PM**, aligning with typical workday engagement:
  - **Peak Open Rate**: 15.94% at 12 AM and 13.24% at 10 AM
  - **Peak Click Rate**: 4.14% at 11 PM and 2.90% at 12 AM
- Lowest engagement occurs during **late evening hours (8 PM â€“ 11 PM)**.

### ğŸ“… Day of the Week Insights
- **Midweek days (Tueâ€“Thu)** yield highest engagement:
  - **Top Click Rates**: Wednesday (2.76%), Tuesday (2.49%), Thursday (2.44%)
- **Fridays and weekends** have lower engagement:
  - Friday Click Rate: 1.40%

### ğŸŒ Country-wise Trends
- **UK and US users** show significantly higher engagement:
  - UK: 12.02% open, 2.47% click
  - US: 11.90% open, 2.44% click
- **European countries (ES, FR)** show much lower response:
  - FR: 4.06% open, 0.80% click

### ğŸ›’ User Past Purchases
- Strong positive correlation between **purchase history and engagement**:
  - Users with 0 past purchases: **0.05% click rate**
  - Users with 10+ past purchases: **4.66%+ click rate**
- Super-engaged users (14â€“22 past purchases) show **click rates above 9%**, with some as high as **100%**.

These patterns indicate that **targeting short, personalized emails during working hours on Tuesdayâ€“Thursday**â€”especially to users with a strong purchase historyâ€”can significantly boost campaign performance.

---
## ğŸ§± Datasets Used

### `email_table`
| Column              | Description                                          |
|---------------------|------------------------------------------------------|
| email_id            | Unique identifier for each email sent               |
| email_text          | Type of text: short (2 paragraphs) or long (4 paragraphs) |
| email_version       | Either â€œpersonalizedâ€ (e.g., â€œHi Johnâ€) or â€œgenericâ€ (e.g., â€œHi,â€) |
| hour                | Local hour when the email was sent                   |
| weekday             | Day of the week the email was sent                   |
| user_country        | Country based on user's IP                           |
| user_past_purchases | Number of past purchases by the user                |

### `email_opened_table`
| Column   | Description                        |
|----------|------------------------------------|
| email_id | Emails that were opened at least once |

### `link_clicked_table`
| Column   | Description                        |
|----------|------------------------------------|
| email_id | Emails where the internal link was clicked |

---

## ğŸ§  Feature Engineering

New features created to enhance model learning:

- `email_version_encoded`, `email_text_encoded` â€” Encoded categorical features  
- `is_weekend` â€” Whether the email was sent on Saturday/Sunday  
- `is_work_hour` â€” Sent between 9 AM and 5 PM  
- `email_sent_bin_encoded` â€” Time of day categorized as night, morning, afternoon, or evening  
- `version_text_combo` â€” Interaction between text and version  
- `user_engagement` â€” Past purchases Ã— opened flag  
- `country_ctr` â€” Average CTR by user country  
- `purchase_bin_encoded` â€” Userâ€™s purchase history bucketed into none, low, med, high

---

## ğŸ¤– Models Trained

| Model                     | Type                  |
|--------------------------|-----------------------|
| `LogisticRegression()`    | Linear                |
| `DecisionTreeClassifier()`| Tree-based            |
| `RandomForestClassifier()`| Ensemble              |
| `GradientBoostingClassifier()` | Boosting        |
| `KNeighborsClassifier()`  | Distance-based        |
| `XGBClassifier()`         | Gradient Boosting (XGBoost) |
| `SVC(probability=True)`   | Support Vector Machine|

---

## ğŸ† Best Performing Model

- **Model**: `SVC (Support Vector Classifier)`  
- **Score**: **97.73%**

---

## ğŸ“ˆ Performance Evaluation

- **Predicted Average CTR**: Slightly lower than historical CTR  
- **Potential CTR Improvement**: **-0.39%**

### ğŸ” What It Tells You

- **Baseline CTR**: How often people click on average (real-world benchmark)  
- **Model Predicted CTR**: What your model thinks the CTR will be (on average)  
- **Improvement (%)**: How much better (or worse) the model is compared to just guessing the baseline CTR for everyone

- If positive, the model is predicting higher CTRs than the average (baseline), suggesting it has learned something useful.
- If negative, it may be overfitting, underperforming, or useless.

Despite high validation accuracy, the negative improvement suggests overfitting or a need for better calibration. This highlights the importance of **contextual performance metrics** (like CTR lift) over raw accuracy.

---
